{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riow1983/pytorch_training/blob/master/CNN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pvt2Eyj_2HL4",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce7700a8-f241-4e29-bce0-ffbd623d3186"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "referece:\n",
        "    https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/ \n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nreferece:\\n    https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/ \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "q9QfZv5n2HMD",
        "colab_type": "code",
        "colab": {},
        "outputId": "8da651b2-b12a-4454-c2a3-bef4c815f133"
      },
      "cell_type": "code",
      "source": [
        "# Pytorch installation for Windows, Pip, Python3.7, CUDA=None\n",
        "#!pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl\n",
        "#!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.1 from https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl (73.6MB)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "You are using pip version 19.0.2, however version 19.0.3 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "  Using cached https://files.pythonhosted.org/packages/fb/01/03fd7e503c16b3dc262483e5555ad40974ab5da8b9879e164b56c1f4ef6f/torchvision-0.2.2.post3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\rhoriuchi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from torchvision) (5.2.0)\n",
            "Requirement already satisfied: six in c:\\users\\rhoriuchi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in c:\\users\\rhoriuchi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\rhoriuchi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from torchvision) (1.15.1)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.2.2.post3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "You are using pip version 19.0.2, however version 19.0.3 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vIbIqJk_2HMJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "b84a95b1-a497-4b78-86d7-ce28252363a5"
      },
      "cell_type": "code",
      "source": [
        "#!python -V"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qO-n1AQE2HMT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nx0lYkcuA5_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pH9Cm8R12HMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f52ca1a-33c2-45a8-f311-da713cf04d8d"
      },
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2b789c9270>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "5eaTVHjy2HMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "edc66028-cd54-4fae-a86c-b224483802e8"
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifardata/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 36402165.16it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t_qJT8Oi2HMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2rBcGJU2HMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# Training\n",
        "n_training_samples = 20000\n",
        "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
        "\n",
        "# Validation\n",
        "n_val_samples = 5000\n",
        "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
        "\n",
        "# Test\n",
        "n_test_samples = 5000\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B4NFFnhF2HMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    \n",
        "    # Our batch shape for input x is (3, 32, 32)\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        # Input channels = 3, output channels = 18\n",
        "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        # 4608 input features, 64 output features (see sizing flow below)\n",
        "        self.fc1 = torch.nn.Linear(18*16*16, 64)\n",
        "        \n",
        "        # 64 input features, 10 output features for our 10 defined classes\n",
        "        self.fc2 = torch.nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Computes the activation of the first convolution\n",
        "        # Size changes from (3, 32, 32) to (18, 32, 32)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        \n",
        "        # Size changes from (18, 32, 32) to (18, 16, 16)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # Reshape data to input to the input layer of the neural net\n",
        "        # Size changes from (18, 16, 16) to (1, 4608)\n",
        "        x = x.view(-1, 18*16*16)\n",
        "        \n",
        "        # Computes the activation of the first fully connected layer\n",
        "        # Size changes from (1, 4608) to (1, 64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        # Computes the second fully connected layer (activation applied later)\n",
        "        # Size changes from (1, 64) to (1, 10)\n",
        "        x = self.fc2(x)\n",
        "        return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKcId7HY2HM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def outputSize(in_size, kernel_size, stride, padding):\n",
        "    output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
        "    return(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YzsdJx7D2HM8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TO start, we'll define our data loaders using the samplers we created above"
      ]
    },
    {
      "metadata": {
        "id": "Gfj6y3G32HM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dataloader takes in a dataset and a sampler for loading (num_workers deals with system level memory)\n",
        "def get_train_loader(batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "    return(train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_O4htlsb2HNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test and validation loaders have constant batch sizes, so we can define them directly\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iv-1PEGb2HNF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy Loss (Log Loss)"
      ]
    },
    {
      "metadata": {
        "id": "YOqcdnOq2HNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    \n",
        "    # Loss function\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    return(loss, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-DRadN8z2HNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "QrRiMmZD2HNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
        "    \n",
        "    # Print all of the hyperparameters of the training iteration:\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    # Get training data\n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    n_batches = len(train_loader)\n",
        "    \n",
        "    # Create our loss and optimizer functions\n",
        "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    \n",
        "    # Time for printing\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    # Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        print_every = n_batches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            \n",
        "            # Get inputs\n",
        "            inputs, labels = data\n",
        "            \n",
        "            # Wrap them in a Variable object\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            # Set the parameters gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass, backward pass, optimize\n",
        "            outputs = net(inputs)\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Print statistics\n",
        "            running_loss += loss_size.data.item() #loss_size.data[0]\n",
        "            total_train_loss += loss_size.data.item() #loss_size.data[0]\n",
        "            \n",
        "            # Print every 10th batch of an epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:\n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                    epoch+1, int(100*(i+1)/n_batches), running_loss / print_every, time.time() - start_time))\n",
        "                # Reset running loss and time\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "                \n",
        "        # At the end of the epoch, do a pass on the validation set \n",
        "        total_val_loss = 0\n",
        "        for inputs, labels in val_loader:\n",
        "            \n",
        "            # Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            # Forward pass\n",
        "            val_outputs = net(inputs)\n",
        "            val_loss_size = loss(val_outputs, labels)\n",
        "            total_val_loss += val_loss_size.data.item() #val_loss_size.data[0]\n",
        "            \n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "        \n",
        "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJv_0zIO2HNP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train actually"
      ]
    },
    {
      "metadata": {
        "id": "WJwmljA82HNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1002
        },
        "outputId": "cfacdd80-063e-4c66-b304-67fa51e0f075"
      },
      "cell_type": "code",
      "source": [
        "CNN = SimpleCNN()\n",
        "trainNet(CNN, batch_size=32, n_epochs=5, learning_rate=0.001)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 32\n",
            "epochs= 5\n",
            "learning_rate= 0.001\n",
            "==============================\n",
            "Epoch 1, 10% \t train_loss: 2.08 took: 1.66s\n",
            "Epoch 1, 20% \t train_loss: 1.87 took: 1.61s\n",
            "Epoch 1, 30% \t train_loss: 1.73 took: 1.64s\n",
            "Epoch 1, 40% \t train_loss: 1.63 took: 1.66s\n",
            "Epoch 1, 50% \t train_loss: 1.58 took: 1.63s\n",
            "Epoch 1, 60% \t train_loss: 1.56 took: 1.65s\n",
            "Epoch 1, 70% \t train_loss: 1.50 took: 1.65s\n",
            "Epoch 1, 80% \t train_loss: 1.44 took: 1.69s\n",
            "Epoch 1, 90% \t train_loss: 1.45 took: 1.67s\n",
            "Validation loss = 1.34\n",
            "Epoch 2, 10% \t train_loss: 1.37 took: 1.97s\n",
            "Epoch 2, 20% \t train_loss: 1.31 took: 2.73s\n",
            "Epoch 2, 30% \t train_loss: 1.32 took: 2.81s\n",
            "Epoch 2, 40% \t train_loss: 1.30 took: 2.55s\n",
            "Epoch 2, 50% \t train_loss: 1.24 took: 2.36s\n",
            "Epoch 2, 60% \t train_loss: 1.33 took: 2.34s\n",
            "Epoch 2, 70% \t train_loss: 1.25 took: 2.33s\n",
            "Epoch 2, 80% \t train_loss: 1.27 took: 2.29s\n",
            "Epoch 2, 90% \t train_loss: 1.30 took: 2.32s\n",
            "Validation loss = 1.25\n",
            "Epoch 3, 10% \t train_loss: 1.19 took: 2.42s\n",
            "Epoch 3, 20% \t train_loss: 1.16 took: 2.35s\n",
            "Epoch 3, 30% \t train_loss: 1.16 took: 2.34s\n",
            "Epoch 3, 40% \t train_loss: 1.16 took: 2.30s\n",
            "Epoch 3, 50% \t train_loss: 1.14 took: 2.32s\n",
            "Epoch 3, 60% \t train_loss: 1.14 took: 2.34s\n",
            "Epoch 3, 70% \t train_loss: 1.16 took: 2.30s\n",
            "Epoch 3, 80% \t train_loss: 1.18 took: 2.32s\n",
            "Epoch 3, 90% \t train_loss: 1.20 took: 2.32s\n",
            "Validation loss = 1.21\n",
            "Epoch 4, 10% \t train_loss: 1.04 took: 2.40s\n",
            "Epoch 4, 20% \t train_loss: 1.08 took: 2.33s\n",
            "Epoch 4, 30% \t train_loss: 1.05 took: 2.33s\n",
            "Epoch 4, 40% \t train_loss: 1.04 took: 2.33s\n",
            "Epoch 4, 50% \t train_loss: 1.07 took: 2.33s\n",
            "Epoch 4, 60% \t train_loss: 1.04 took: 2.36s\n",
            "Epoch 4, 70% \t train_loss: 1.05 took: 2.40s\n",
            "Epoch 4, 80% \t train_loss: 1.08 took: 2.52s\n",
            "Epoch 4, 90% \t train_loss: 1.02 took: 2.52s\n",
            "Validation loss = 1.19\n",
            "Epoch 5, 10% \t train_loss: 0.94 took: 2.43s\n",
            "Epoch 5, 20% \t train_loss: 0.95 took: 2.36s\n",
            "Epoch 5, 30% \t train_loss: 0.96 took: 2.37s\n",
            "Epoch 5, 40% \t train_loss: 0.92 took: 2.36s\n",
            "Epoch 5, 50% \t train_loss: 0.96 took: 2.39s\n",
            "Epoch 5, 60% \t train_loss: 0.96 took: 2.35s\n",
            "Epoch 5, 70% \t train_loss: 0.97 took: 2.37s\n",
            "Epoch 5, 80% \t train_loss: 0.98 took: 2.37s\n",
            "Epoch 5, 90% \t train_loss: 0.99 took: 2.37s\n",
            "Validation loss = 1.16\n",
            "Training finished, took 121.34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RYH7TTlL6Rc3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save"
      ]
    },
    {
      "metadata": {
        "id": "uh3Bf0NA6Ssb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(CNN.state_dict(), \"simpleCNN.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwkwDrs-6apW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "420b1ced-9728-455b-dfbb-29d7e1d05ef2"
      },
      "cell_type": "code",
      "source": [
        "#!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifardata  sample_data\tsimpleCNN.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JRy6XQ6s7rkU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RZoFMzp-7xVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d3d821a9-c334-4a7b-f801-dbbe19e1a655"
      },
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "model.load_state_dict(torch.load(\"simpleCNN.pt\"))\n",
        "model.eval()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "943m_MH9_j5f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test"
      ]
    },
    {
      "metadata": {
        "id": "iv2y2koO8TIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for inputs, labels in test_loader:\n",
        "    # Wrap tensors in Variables\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "    # Forward pass\n",
        "    test_outputs = model(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zKBWf-UnBHWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbc41e2b-97bf-4f22-955e-f4e4384fd0ce"
      },
      "cell_type": "code",
      "source": [
        "test_outputs.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "S4foTEr6_vRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11b81d7e-bf4b-45a6-ebf8-88f6be3d0f04"
      },
      "cell_type": "code",
      "source": [
        "torch.max(test_outputs, 1)[1]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 5, 8, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "QaNrpZux_y6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5062f67c-7225-400e-d834-4bbbde218245"
      },
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 8, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "1DeuE9DoCFY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3743b046-5488-4357-b72e-4b0c7d5a6c67"
      },
      "cell_type": "code",
      "source": [
        "torch.max(test_outputs, 1)[1] == labels"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}